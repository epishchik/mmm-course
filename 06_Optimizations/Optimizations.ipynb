{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250904f3-aba8-43bc-9e56-bd25aa220993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"./ephemeral/HF\"\n",
    "os.environ[\"HF_HUB_DISABLE_XET\"] = \"1\"\n",
    "os.environ[\"HF_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34a470f-f803-403c-b47f-321c7a9570e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_25_quantizations = [\"\", \"-AWQ\", \"-GPTQ-Int4\", \"-GPTQ-Int8\"]\n",
    "qwen_25_default_name = \"Qwen/Qwen2.5-3B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0f6d5-4af7-40dd-8b71-f49712a5b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34304d82-cf19-4094-b3bb-5ec7f7b07139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, model_name, gpu_mem_util=0.5, **kwargs):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self.gpu_mem_util = gpu_mem_util\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.model.generate(*args, **kwargs)\n",
    "\n",
    "    def __enter__(self, *args, **kwargs):\n",
    "        self.model = LLM(self.model_name, gpu_memory_utilization=self.gpu_mem_util, max_model_len=5000, **self.kwargs)\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        del self.model\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f51a3df-4be1-4e19-89f7-7bb043f7855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class TimeManagement:\n",
    "    def __init__(self, name, output_dict):\n",
    "        self.output_dict = output_dict\n",
    "        self.name = name\n",
    "    \n",
    "    def __enter__(self, *args, **kwargs):\n",
    "        self.begin = datetime.now()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args, **kwargs):\n",
    "        self.output_dict[self.name] = (datetime.now() - self.begin).total_seconds()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1097390-2f0b-4225-a3d4-92256bfa5429",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = {}\n",
    "token_length_dict = {}\n",
    "\n",
    "def function_check(model_name):\n",
    "    print(f\"!!!BEGIN CHECKING {model_name}!!!\")\n",
    "    with Model(model_name) as model:\n",
    "        model(\"Привет, медвед!\", SamplingParams(max_tokens=1000, temperature=0.7))\n",
    "\n",
    "        with TimeManagement(model_name, time_dict):\n",
    "            result = model(\n",
    "                \"Напиши длинную историю России\", \n",
    "                SamplingParams(max_tokens=8000, temperature=0.7)\n",
    "            )\n",
    "\n",
    "        token_length_dict[model_name] = len(result[0].outputs[0].token_ids)\n",
    "\n",
    "\n",
    "for quantization in qwen_25_quantizations:\n",
    "    function_check(qwen_25_default_name + quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc7eac-d079-4de0-a458-698376ff0ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "headers = [\"Name\", \"TPS\", \"Tokens\", \"Seconds\"]\n",
    "results = []\n",
    "\n",
    "\n",
    "for name in time_dict.keys():\n",
    "    results.append(\n",
    "        [\n",
    "            name,\n",
    "            f\"{token_length_dict[name]/time_dict[name]:.2f}\",\n",
    "            token_length_dict[name],\n",
    "            time_dict[name]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "print(\n",
    "    tabulate(\n",
    "        results,\n",
    "        headers=headers,\n",
    "        tablefmt=\"grid\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121e57e5-7031-4dea-8f88-1b8adf3beb88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in [4, 8, 16, 24]:\n",
    "    with Model(\n",
    "        \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "        speculative_config={\n",
    "            \"model\": \"Qwen/Qwen2.5-3B-Instruct-GPTQ-Int4\",\n",
    "            \"num_speculative_tokens\": k,\n",
    "        }\n",
    "    ) as model_1:\n",
    "        name = f\"Speculative_decoding {k}\"\n",
    "        with TimeManagement(name, time_dict):\n",
    "            result = model_1(\n",
    "                \"Напиши длинную историю России\", \n",
    "                SamplingParams(\n",
    "                    max_tokens=8000, \n",
    "                    temperature=0,\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        print(f\"!!!!! + {name} !!!!!\")\n",
    "        print(result[0].outputs[0].text)\n",
    "        token_length_dict[name] = len(result[0].outputs[0].token_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
